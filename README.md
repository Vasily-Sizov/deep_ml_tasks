# Machine Learning

https://www.deep-ml.com/collections/Machine%20Learning

Этот сборник задач укрепит ваши знания в области машинного обучения благодаря реализации основных алгоритмов с нуля с использованием Python и NumPy. Вы будете решать задачи линейной регрессии, деревьев решений, SVM, кластеризации, глубокого обучения и многое другое, уделяя особое внимание математике, оптимизации и реальным приложениям. Независимо от того, являетесь ли вы новичком или экспертом, эти практические упражнения помогут вам отточить свои навыки и углубить понимание машинного обучения.

## 1. Linear Algebra

- 1.1 Matrix-Vector Dot Product - Done
- 1.2 Transpose of a Matrix - Done
- 1.3 Dot Product Calculator
- 1.4 Scalar Multiplication of a Matrix
- 1.5 Calculate Cosine Similarity Between Vectors
- 1.6 Calculate Mean by Row or Column
- 1.7 Calculate Eigenvalues of a Matrix
- 1.8 Calculate 2x2 Matrix Inverse
- 1.9 Matrix times Matrix

## 2. Probability and Statistics

- 2.1 Poisson Distribution Probability Calculator
- 2.2 Binomial Distribution Probability
- 2.3 Normal Distribution PDF Calculator
- 2.4 Descriptive Statistics Calculator
- 2.5 Calculate Covariance Matrix

## 3. Optimization Techniques
- 3.1 Linear Regression Using Gradient Descent - Done
- 3.2 Implement Gradient Descent Variants with MSE Loss - Done
- 3.3 Implement Adam Optimization Algorithm
- 3.4 Implement Lasso Regression using Gradient Descent

## 4. Model Evaluation
- 4.1 Generate a Confusion Matrix for Binary Classification - Done
- 4.2 Calculate Accuracy Score - Done
- 4.3 Implement Precision Metric - Done
- 4.4 Implement Recall Metric in Binary Classification - Done
- 4.5 Implement F-Score Calculation for Binary Classification - Done
- 4.6 Calculate R-squared for Regression Analysis - Done
- 4.7 Calculate Mean Absolute Error (MAE) - Done
- 4.8 Calculate Root Mean Square Error (RMSE) - Done
- 4.9 Implement K-Fold Cross-Validation - Done
- 4.10 Calculate Performance Metrics for a Classification Model - Not
- 4.11 Implementation of Log Softmax Function
- 4.12 Implement ReLU Activation Function

## 5. Classification & Regression Techniques
- 5.1 Linear Regression Using Normal Equation - Done
- 5.2 Linear Regression Using Gradient Descent  - Done
- 5.3 Binary Classification with Logistic Regression  - Done
- 5.4 Calculate Jaccard Index for Binary Classification
- 5.5 Pegasos Kernel SVM Implementation
- 5.6 Implement AdaBoost Fit Method
- 5.7 Softmax Activation Function Implementation

## 6. Unsupervised Learning
- 6.1 KL Divergence Between Two Normal Distributions
- 6.2 Principal Component Analysis (PCA) Implementation
- 6.3 K-Means Clustering

## 7. Deep Learning
- 7.1 Single Neuron
- 7.2 Sigmoid Activation Function Understanding
- 7.3 Softmax Activation Function Implementation
- 7.4 Implementation of Log Softmax Function
- 7.5 Implement ReLU Activation Function
- 7.6 Simple Convolutional 2D Layer
- 7.7 Implementing a Simple RNN

# Обязательно сделать:
- Регрессию и классификацию (логрег)
- Повторить O(N) - нотацию
- Типы
- gIL
- треды и мультипроцессы и асинхронность